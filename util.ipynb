{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility notebook for stats calculation, prompts sampling and post-processing for GPT-3 generated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3012\n",
      "187611\n",
      "62.287848605577686\n"
     ]
    }
   ],
   "source": [
    "# train stats\n",
    "train_file = open('eca-train-cleaned.tsv')\n",
    "train_tsv = csv.reader(train_file, delimiter=\"\\t\")\n",
    "total_length = 0\n",
    "total = 0\n",
    "for i, line in enumerate(train_tsv):\n",
    "    if i == 0: continue\n",
    "    total += 1\n",
    "    total_length += len(line[0].split())\n",
    "    # print(len(line[0].split()))\n",
    "\n",
    "print(total)\n",
    "print(total_length)\n",
    "print(total_length / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376\n",
      "23444\n",
      "62.351063829787236\n"
     ]
    }
   ],
   "source": [
    "# dev stats\n",
    "dev_file = open('eca-dev-cleaned.tsv')\n",
    "dev_tsv = csv.reader(dev_file, delimiter=\"\\t\")\n",
    "total_length = 0\n",
    "total = 0\n",
    "for i, line in enumerate(dev_tsv):\n",
    "    if i == 0: continue\n",
    "    total += 1\n",
    "    total_length += len(line[0].split())\n",
    "    # print(len(line[0].split()))\n",
    "\n",
    "print(total)\n",
    "print(total_length)\n",
    "print(total_length / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319\n",
      "19210\n",
      "60.21943573667711\n"
     ]
    }
   ],
   "source": [
    "# test stats\n",
    "test_file = open('eca-test-cleaned.tsv')\n",
    "test_tsv = csv.reader(test_file, delimiter=\"\\t\")\n",
    "total_length = 0\n",
    "total = 0\n",
    "for i, line in enumerate(test_tsv):\n",
    "    if i == 0: continue\n",
    "    total += 1\n",
    "    total_length += len(line[0].split())\n",
    "    # print(len(line[0].split()))\n",
    "\n",
    "print(total)\n",
    "print(total_length)\n",
    "print(total_length / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376\n",
      "12121\n",
      "32.236702127659576\n"
     ]
    }
   ],
   "source": [
    "# train stats\n",
    "train_file = open('eca-dev-cleaned-exp-TRS-4.tsv')\n",
    "train_tsv = csv.reader(train_file, delimiter=\"\\t\")\n",
    "total_length = 0\n",
    "total = 0\n",
    "for i, line in enumerate(train_tsv):\n",
    "    if i == 0: continue\n",
    "    total += 1\n",
    "    total_length += len(line[-1].strip().split())\n",
    "    # print(len(line[-1].strip().split()))\n",
    "    # print((line[-1].strip()))\n",
    "    # print(len(line[0].split()))\n",
    "\n",
    "print(total)\n",
    "print(total_length)\n",
    "print(total_length / total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample data for choosing prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3012 entries, 0 to 3011\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   document       3012 non-null   object\n",
      " 1   token_label    3012 non-null   object\n",
      " 2   emotion_label  3012 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 70.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('eca-train-cleaned.tsv', delimiter=\"\\t\")\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>token_label</th>\n",
       "      <th>emotion_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>\"Look here \" he began and he was surprised at ...</td>\n",
       "      <td>O O O O O O O O B-EMO O B-CAU I-CAU I-CAU I-CA...</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              document  \\\n",
       "757  \"Look here \" he began and he was surprised at ...   \n",
       "\n",
       "                                           token_label emotion_label  \n",
       "757  O O O O O O O O B-EMO O B-CAU I-CAU I-CAU I-CA...      surprise  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df['emotion_label'] == 'surprise'].sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 319 entries, 0 to 318\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   document       319 non-null    object\n",
      " 1   token_label    319 non-null    object\n",
      " 2   emotion_label  319 non-null    object\n",
      " 3   explanation    319 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 10.1+ KB\n"
     ]
    }
   ],
   "source": [
    "two_shot_df = pd.read_csv('eca-test-cleaned-exp-TRS-2.tsv', delimiter=\"\\t\")\n",
    "two_shot_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.20689655172414\n"
     ]
    }
   ],
   "source": [
    "len_lst = []\n",
    "for exp in two_shot_df['explanation']:\n",
    "    # print(len(exp))\n",
    "    len_lst.append(len(str(exp).split()))\n",
    "\n",
    "print(sum(len_lst) / len(len_lst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-process raw GPT-3 generations to contain only explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 656 entries, 0 to 655\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   document       656 non-null    object\n",
      " 1   token_label    656 non-null    object\n",
      " 2   emotion-label  656 non-null    object\n",
      " 3   explanation    656 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 20.6+ KB\n"
     ]
    }
   ],
   "source": [
    "split = 'train'\n",
    "shot = 'TRS-4'\n",
    "shot_raw_df = pd.read_csv('./model/GPT3/data/ghazi/fold0/eca-{}-cleaned-exp-{}-raw.tsv'.format(split, shot), delimiter=\"\\t\")\n",
    "shot_raw_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " In the text, the cause is that Tolkien was happy to find anyone who could appreciate his writing. The emotion mentioned is that Tolkien thought of an audience when he wrote. The cause result in the emotion mentioned because when an author is happy to find someone who could appreciate his writing, it means that the author thought of an audience when he wrote. Therefore, the cause leads to the emotion mentioned in the text.\n",
      " In the text, the cause is that the woman was worried about having to manage the farm by herself again. The emotion mentioned is that the woman was worried. The cause results in the emotion mentioned because the woman was worried about having to manage the farm by herself again. The cause results in the emotion mentioned because the woman was worried about having to manage the farm by herself again.\n"
     ]
    }
   ],
   "source": [
    "explanations = []\n",
    "for sent in shot_raw_df['explanation']:\n",
    "    if len(sent.split('The cause results in the emotion mentioned because')) != 2:\n",
    "        explanations.append(sent)\n",
    "        print(sent)\n",
    "    else:\n",
    "        # print(sent.split('The cause results in the emotion mentioned because')[1])\n",
    "        explanations.append(sent.split('The cause results in the emotion mentioned because')[1])\n",
    "shot_raw_df['explanations'] = explanations\n",
    "shot_raw_df = shot_raw_df.drop(['explanation'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "shot_raw_df.to_csv('./model/GPT3/data/ghazi/fold0/eca-{}-cleaned-exp-{}.tsv'.format(split,shot), sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " In the text, the cause is that the sisters thought of possible further deterioration. The emotion mentioned is that the sisters looked alarmed. The cause results in emotion mentioned because when people think of something that could make their situation worse, they often become alarmed. In this case, the sisters are worried that things could get worse for them.\n",
      " In the text, the cause is that the wife of former Beirut hostage Jackie Mann died of lung cancer. The emotion mentioned is that the author was heartbroken she could not see her before she died of lung cancer. The cause results emotion mentioned because the author and the wife of former Beirut hostage Jackie Mann were close friends. Therefore, when the wife of former Beirut hostage Jackie Mann died, the author was heartbroken that she was not able to see her before she died.\n",
      " In the text, the cause is that McGoldrick signed on for four years after talks with Highbury boss George Graham. The emotion mentioned is that McGoldrick was delighted that it all went through so smoothly. The cause result in the emotion mentioned because signing on for four years is a big decision and it usually takes a lot of time and effort to go through the process. However, in this case, it all went through smoothly and McGoldrick was delighted with the outcome.\n",
      " In the text, the cause is that the woman did not know the man well. The emotion mentioned is that the woman thought that the man was cross with her. The cause result in the emotion mentioned because when the woman did not know the man well, she thought that the man's behavior was due to the fact that he was cross with her.\n",
      " In the text, the cause is that the war dragged on. The emotion mentioned is that Modigliani's horror at the waste of life increased. The cause result in the emotion mentioned because as the war dragged on, more and more people were dying and being injured. This increase in death and destruction horrified Modigliani.\n",
      " In the text, the cause is that the author had no time to feel nervous about facing Steve Bull and Andy Mutch. The emotion mentioned is that the author was in agony. The cause resulted in the emotion mentioned because the author had no time to feel nervous about the upcoming meeting with Steve Bull and Andy Mutch. The author was in agony because he knew that he would have to face them without any preparation.\n",
      " In the text, the cause is that the heartbreak of her troubled marriage still haunts her. The emotion mentioned is that she raised a grin when Prince Harry waved from their car in London. The cause results in the emotion mentioned because the mother was harsh to her daughter during the weeks. The emotion mentioned is that the mother was sorry. The cause results in the emotion mentioned because the mother did not wish the night to be made of any harshness towards each other. Therefore, after the mother was harsh to her daughter, she was sorry that she had been unkind to her daughter.\n"
     ]
    }
   ],
   "source": [
    "# gpt3 prompting for ghazi data\n",
    "for fold in ['fold1', 'fold2', 'fold3', 'fold4']:\n",
    "    for split in ['train', 'dev']:\n",
    "        for shot in ['TRS-2', 'TRS-4']:\n",
    "            # split = 'train'\n",
    "            # shot = 'TRS-4'\n",
    "            shot_raw_df = pd.read_csv('./model/GPT3/data/ghazi/{}/eca-{}-cleaned-exp-{}-raw.tsv'.format(fold, split, shot), delimiter=\"\\t\")\n",
    "            # shot_raw_df.info()\n",
    "\n",
    "            explanations = []\n",
    "            for sent in shot_raw_df['explanation']:\n",
    "                if len(sent.split('The cause results in the emotion mentioned because')) != 2:\n",
    "                    explanations.append(sent)\n",
    "                    print(sent)\n",
    "                else:\n",
    "                    # print(sent.split('The cause results in the emotion mentioned because')[1])\n",
    "                    explanations.append(sent.split('The cause results in the emotion mentioned because')[1])\n",
    "            shot_raw_df['explanations'] = explanations\n",
    "            shot_raw_df = shot_raw_df.drop(['explanation'], axis=1)\n",
    "\n",
    "            shot_raw_df.to_csv('./model/GPT3/data/ghazi/{}/eca-{}-cleaned-exp-{}.tsv'.format(fold, split,shot), sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Significance test (paired t-test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=-3.484667142363774, pvalue=0.008262824741817632, df=8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# effectiveness of bi-lstm\n",
    "bect_nolstm = [0.2097, 0.2142,\t0.2119,\t0.4633,\t0.386,\t0.4209,\t0.2287,\t0.2381,\t0.2332]\n",
    "bect = [0.2143,\t0.223,\t0.2186,\t0.4856,\t0.39,\t0.4323,\t0.2265,\t0.2499,\t0.2376]\n",
    "stats.ttest_rel(bect_nolstm, bect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### COMET-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=-3.0262961673342823, pvalue=0.02920498051254723, df=5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ECSE+ECSP: BECT VS Causes\n",
    "Causes = [0.2195,\t0.2275,\t0.2233, 0.2272,\t0.2507,\t0.2383]\n",
    "bect = [0.2143,\t0.223,\t0.2186, 0.2265,\t0.2499,\t0.2376]\n",
    "stats.ttest_rel(bect, Causes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GLUCOSE-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=-7.910330289353436, pvalue=0.015608076802147201, df=2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ECSE: (dim1-spec VS BECT)\n",
    "dim1_spec = [0.2274, 0.2314, 0.2293]\n",
    "bect = [0.2143,\t0.223,\t0.2186]\n",
    "stats.ttest_rel(bect, dim1_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=0.18002778497876945, pvalue=0.8737202026861619, df=2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EESE: (dim7-spec VS BECT)\n",
    "dim7_spec = [0.4792, 0.3944, 0.4326]\n",
    "bect = [0.4856,\t0.39,\t0.4323]\n",
    "stats.ttest_rel(bect, dim7_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=-1.0113796089977531, pvalue=0.418294575369641, df=2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ECSP: (dim2-spec VS BECT)\n",
    "dim2_spec = [0.2242,0.2599,\t0.2407]\n",
    "bect = [0.2265,\t0.2499,\t0.2376]\n",
    "stats.ttest_rel(bect, dim2_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GPT3-prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=-16.010861734483587, pvalue=0.0038782730768579655, df=2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ECSE: (TRS-4 VS BECT-doc)\n",
    "TRS_4 = [0.2594,0.3069,\t0.281]\n",
    "bect_doc = [0.2349,\t0.2765,\t0.2539]\n",
    "stats.ttest_rel(bect_doc, TRS_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=-56.615384615386574, pvalue=0.00031183718060284505, df=2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ECSP: (TRS-4 VS BECT-doc)\n",
    "TRS_4 = [0.2784,0.2952,\t0.2865]\n",
    "bect_doc = [0.2531,\t0.2714,\t0.262]\n",
    "stats.ttest_rel(bect_doc, TRS_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=1.8014990349722022, pvalue=0.2134165967347317, df=2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EESE: (TRS-2-256 vs bect-doc-256)\n",
    "TRS_2 = [0.4953, 0.5339, 0.5138]\n",
    "bect_doc = [0.4969, 0.5344, 0.514]\n",
    "stats.ttest_rel(bect_doc, TRS_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=-7.630998044000648, pvalue=0.01674259148268539, df=2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ECSE: (bect-doc vs bect-doc-Causes)\n",
    "bect_doc_Causes = [0.2524, 0.3014, 0.2746]\n",
    "bect_doc = [0.2448,\t0.2893,\t0.2645]\n",
    "stats.ttest_rel(bect_doc, bect_doc_Causes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=-15.496543393375081, pvalue=0.004138356507618268, df=2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EESE: (bect-doc vs bect-doc-Causes)\n",
    "bect_doc = [0.4955,\t0.5212,\t0.5077]\n",
    "bect_doc_Causes = [0.4967,\t0.5227,\t0.5091]\n",
    "stats.ttest_rel(bect_doc, bect_doc_Causes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=26.14939191787053, pvalue=0.0014592355275277777, df=2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ECSP: (bect-doc vs bect-doc-Causes)\n",
    "bect_doc = [0.2777,\t0.2893,\t0.2833]\n",
    "bect_doc_Causes = [0.2672,\t0.2801,\t0.2733]\n",
    "stats.ttest_rel(bect_doc, bect_doc_Causes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadList(path):\n",
    "    pkl_file = open(path, 'rb')\n",
    "    segContent = pickle.load(pkl_file)\n",
    "    pkl_file.close()\n",
    "    return segContent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = loadList('eca_sti_data.pkl')\n",
    "data_set_ids = list(range(len(data_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_set_ids[4*164: ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(0.2 * len(data_set_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
