{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility notebook for stats calculation, prompts sampling and post-processing for GPT-3 generated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3012\n",
      "187611\n",
      "62.287848605577686\n"
     ]
    }
   ],
   "source": [
    "# train stats\n",
    "train_file = open('eca-train-cleaned.tsv')\n",
    "train_tsv = csv.reader(train_file, delimiter=\"\\t\")\n",
    "total_length = 0\n",
    "total = 0\n",
    "for i, line in enumerate(train_tsv):\n",
    "    if i == 0: continue\n",
    "    total += 1\n",
    "    total_length += len(line[0].split())\n",
    "    # print(len(line[0].split()))\n",
    "\n",
    "print(total)\n",
    "print(total_length)\n",
    "print(total_length / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376\n",
      "23444\n",
      "62.351063829787236\n"
     ]
    }
   ],
   "source": [
    "# dev stats\n",
    "dev_file = open('eca-dev-cleaned.tsv')\n",
    "dev_tsv = csv.reader(dev_file, delimiter=\"\\t\")\n",
    "total_length = 0\n",
    "total = 0\n",
    "for i, line in enumerate(dev_tsv):\n",
    "    if i == 0: continue\n",
    "    total += 1\n",
    "    total_length += len(line[0].split())\n",
    "    # print(len(line[0].split()))\n",
    "\n",
    "print(total)\n",
    "print(total_length)\n",
    "print(total_length / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319\n",
      "19210\n",
      "60.21943573667711\n"
     ]
    }
   ],
   "source": [
    "# test stats\n",
    "test_file = open('eca-test-cleaned.tsv')\n",
    "test_tsv = csv.reader(test_file, delimiter=\"\\t\")\n",
    "total_length = 0\n",
    "total = 0\n",
    "for i, line in enumerate(test_tsv):\n",
    "    if i == 0: continue\n",
    "    total += 1\n",
    "    total_length += len(line[0].split())\n",
    "    # print(len(line[0].split()))\n",
    "\n",
    "print(total)\n",
    "print(total_length)\n",
    "print(total_length / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376\n",
      "12121\n",
      "32.236702127659576\n"
     ]
    }
   ],
   "source": [
    "# train stats\n",
    "train_file = open('eca-dev-cleaned-exp-TRS-4.tsv')\n",
    "train_tsv = csv.reader(train_file, delimiter=\"\\t\")\n",
    "total_length = 0\n",
    "total = 0\n",
    "for i, line in enumerate(train_tsv):\n",
    "    if i == 0: continue\n",
    "    total += 1\n",
    "    total_length += len(line[-1].strip().split())\n",
    "    # print(len(line[-1].strip().split()))\n",
    "    # print((line[-1].strip()))\n",
    "    # print(len(line[0].split()))\n",
    "\n",
    "print(total)\n",
    "print(total_length)\n",
    "print(total_length / total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample data for choosing prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3012 entries, 0 to 3011\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   document       3012 non-null   object\n",
      " 1   token_label    3012 non-null   object\n",
      " 2   emotion_label  3012 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 70.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('eca-train-cleaned.tsv', delimiter=\"\\t\")\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>token_label</th>\n",
       "      <th>emotion_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>\"Look here \" he began and he was surprised at ...</td>\n",
       "      <td>O O O O O O O O B-EMO O B-CAU I-CAU I-CAU I-CA...</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              document  \\\n",
       "757  \"Look here \" he began and he was surprised at ...   \n",
       "\n",
       "                                           token_label emotion_label  \n",
       "757  O O O O O O O O B-EMO O B-CAU I-CAU I-CAU I-CA...      surprise  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df['emotion_label'] == 'surprise'].sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 319 entries, 0 to 318\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   document       319 non-null    object\n",
      " 1   token_label    319 non-null    object\n",
      " 2   emotion_label  319 non-null    object\n",
      " 3   explanation    319 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 10.1+ KB\n"
     ]
    }
   ],
   "source": [
    "two_shot_df = pd.read_csv('eca-test-cleaned-exp-TRS-2.tsv', delimiter=\"\\t\")\n",
    "two_shot_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.20689655172414\n"
     ]
    }
   ],
   "source": [
    "len_lst = []\n",
    "for exp in two_shot_df['explanation']:\n",
    "    # print(len(exp))\n",
    "    len_lst.append(len(str(exp).split()))\n",
    "\n",
    "print(sum(len_lst) / len(len_lst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-process raw GPT-3 generations to contain only explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 376 entries, 0 to 375\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   document       376 non-null    object\n",
      " 1   token_label    376 non-null    object\n",
      " 2   emotion_label  376 non-null    object\n",
      " 3   explanation    376 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 11.9+ KB\n"
     ]
    }
   ],
   "source": [
    "split = 'dev'\n",
    "shot = 'TRS-2'\n",
    "shot_raw_df = pd.read_csv('eca-{}-cleaned-exp-{}-raw.tsv'.format(split, shot), delimiter=\"\\t\")\n",
    "shot_raw_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " In the text, the cause is that the mother was worried about telling her husband that she had a daughter, not a son. The emotion mentioned is that the husband was delighted when he looked into his daughter's eyes. The cause results in the emotion mentioned because the husband wanted a son, but when he saw his daughter's eyes, he was delighted. The cause results in the emotion mentioned because the husband was happy to have a daughter, even though he originally wanted a son.\n"
     ]
    }
   ],
   "source": [
    "explanations = []\n",
    "for sent in shot_raw_df['explanation']:\n",
    "    if len(sent.split('The cause results in the emotion mentioned because')) != 2:\n",
    "        explanations.append(sent)\n",
    "        print(sent)\n",
    "    else:\n",
    "        # print(sent.split('The cause results in the emotion mentioned because')[1])\n",
    "        explanations.append(sent.split('The cause results in the emotion mentioned because')[1])\n",
    "shot_raw_df['explanations'] = explanations\n",
    "shot_raw_df = shot_raw_df.drop(['explanation'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "shot_raw_df.to_csv('eca-{}-cleaned-exp-{}.tsv'.format(split,shot), sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Significance test (paired t-test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=-3.484667142363774, pvalue=0.008262824741817632, df=8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# effectiveness of bi-lstm\n",
    "bect_nolstm = [0.2097, 0.2142,\t0.2119,\t0.4633,\t0.386,\t0.4209,\t0.2287,\t0.2381,\t0.2332]\n",
    "bect = [0.2143,\t0.223,\t0.2186,\t0.4856,\t0.39,\t0.4323,\t0.2265,\t0.2499,\t0.2376]\n",
    "stats.ttest_rel(bect_nolstm, bect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### COMET-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=-3.0262961673342823, pvalue=0.02920498051254723, df=5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ECSE+ECSP: BECT VS Causes\n",
    "Causes = [0.2195,\t0.2275,\t0.2233, 0.2272,\t0.2507,\t0.2383]\n",
    "bect = [0.2143,\t0.223,\t0.2186, 0.2265,\t0.2499,\t0.2376]\n",
    "stats.ttest_rel(bect, Causes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GLUCOSE-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=-7.910330289353436, pvalue=0.015608076802147201, df=2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ECSE: (dim1-spec VS BECT)\n",
    "dim1_spec = [0.2274, 0.2314, 0.2293]\n",
    "bect = [0.2143,\t0.223,\t0.2186]\n",
    "stats.ttest_rel(bect, dim1_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=0.18002778497876945, pvalue=0.8737202026861619, df=2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EESE: (dim7-spec VS BECT)\n",
    "dim7_spec = [0.4792, 0.3944, 0.4326]\n",
    "bect = [0.4856,\t0.39,\t0.4323]\n",
    "stats.ttest_rel(bect, dim7_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=-1.0113796089977531, pvalue=0.418294575369641, df=2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ECSP: (dim2-spec VS BECT)\n",
    "dim2_spec = [0.2242,0.2599,\t0.2407]\n",
    "bect = [0.2265,\t0.2499,\t0.2376]\n",
    "stats.ttest_rel(bect, dim2_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GPT3-prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=-16.010861734483587, pvalue=0.0038782730768579655, df=2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ECSE: (TRS-4 VS BECT-doc)\n",
    "TRS_4 = [0.2594,0.3069,\t0.281]\n",
    "bect_doc = [0.2349,\t0.2765,\t0.2539]\n",
    "stats.ttest_rel(bect_doc, TRS_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=-56.615384615386574, pvalue=0.00031183718060284505, df=2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ECSP: (TRS-4 VS BECT-doc)\n",
    "TRS_4 = [0.2784,0.2952,\t0.2865]\n",
    "bect_doc = [0.2531,\t0.2714,\t0.262]\n",
    "stats.ttest_rel(bect_doc, TRS_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=1.8014990349722022, pvalue=0.2134165967347317, df=2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EESE: (TRS-2-256 vs bect-doc-256)\n",
    "TRS_2 = [0.4953, 0.5339, 0.5138]\n",
    "bect_doc = [0.4969, 0.5344, 0.514]\n",
    "stats.ttest_rel(bect_doc, TRS_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
