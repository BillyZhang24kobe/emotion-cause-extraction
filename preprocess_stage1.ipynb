{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook converts data from xml format to tsv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = './NTCIR-ECA13-3000/emotion_cause_english_train.xml'\n",
    "test_path = './NTCIR-ECA13-3000/emotion_cause_english_test.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ET.parse(test_path)\n",
    "root = tree.getroot()\n",
    "prefix = '{http://www.w3.org/2009/10/emotionml}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for document in root.findall(prefix+'emotion'):\n",
    "    docID = document.get('id')\n",
    "    emotion = document.find(prefix+'category').get('name')\n",
    "    e_value = document.find(prefix+'category').get('value')\n",
    "    num_clauses = 0\n",
    "    emotion_clauseID = -1\n",
    "    cause_clauseID = -1\n",
    "    c_list = []\n",
    "    for clause in document.iter(prefix+'clause'):\n",
    "        num_clauses += 1\n",
    "        emotion_begin = -1\n",
    "        emotion_length = -1\n",
    "        cause_begin = -1\n",
    "        cause_length = -1\n",
    "        c_list.append(clause.get('id'))\n",
    "        if clause.get('keywords') == 'Y':\n",
    "            emotion_clauseID = clause.get('id')\n",
    "            c_list.append(clause.find(prefix+'keywords').text)\n",
    "            emotion_begin = clause.find(prefix+'keywords').get('keywords-begin')\n",
    "            emotion_length = clause.find(prefix+'keywords').get('keywords-lenth')\n",
    "        else:\n",
    "            c_list.append('null')\n",
    "            \n",
    "        if clause.get('cause') == 'Y':\n",
    "            cause_clauseID = clause.get('id')\n",
    "            c_list.append(clause.find(prefix+'cause').text)\n",
    "            cause_begin = clause.find(prefix+'cause').get('begin')\n",
    "            cause_length = clause.find(prefix+'cause').get('lenth')\n",
    "        else:\n",
    "            c_list.append('null')\n",
    "        \n",
    "        c_list.append(clause.find(prefix+'text').text)\n",
    "        if emotion_begin == -1:\n",
    "            c_list.append('null')\n",
    "        else:\n",
    "            c_list.append((emotion_begin, emotion_length))\n",
    "\n",
    "        if cause_begin == -1:\n",
    "            c_list.append('null')\n",
    "        else:\n",
    "            c_list.append((cause_begin, cause_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert JSON format into tab-seperated tsv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('eca_test.json', 'r') as test:\n",
    "    test_data = json.load(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('eca_train.json', 'r') as train:\n",
    "    train_data = json.load(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_data['emotionml']['emotion'][0]['clause'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add token-level label to the tsv file for both train and test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate tokens for train file\n",
    "with open('./eca-train.tsv', 'wt') as out_file:\n",
    "    tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
    "    tsv_writer.writerow(['document', 'token_label', 'emotion-label'])\n",
    "    for d, document in enumerate(train_data['emotionml']['emotion']):\n",
    "        emotion = document['category']['_name']\n",
    "        doc = []\n",
    "        doc_label = []\n",
    "        if 'clause' not in train_data['emotionml']['emotion'][d]: continue\n",
    "        for i, clause in enumerate(train_data['emotionml']['emotion'][d]['clause']):\n",
    "            # raw text\n",
    "            if 'text' not in clause: continue\n",
    "            text = clause['text'].split(' ')  # a list of tokens\n",
    "#             if i+1 != len(test_data['emotionml']['emotion'][d]['clause']):\n",
    "#                 text += ['[SEP]']\n",
    "            \n",
    "            # labels for each word in the raw data: 'O', 'B-CAU', 'I-CAU', 'B-EMO', 'I-EMO', '[CLS]', '[SEP]'\n",
    "            if clause['_cause'] == 'N' and clause['_keywords'] == 'N':\n",
    "                token_label = ['O'] * len(text)\n",
    "            else:\n",
    "                token_label = text.copy()\n",
    "                if clause['_cause'] == 'Y':\n",
    "                    cause_begin_charID = int(clause['cause']['_begin'])  # characater index\n",
    "                    cause_length = int(clause['cause']['_lenth'])\n",
    "                    begin_cause_wordID = len(clause['text'][:cause_begin_charID-1].split())  # word index for beginning\n",
    "                    end_cause_wordID = begin_cause_wordID + len(clause['text'][cause_begin_charID-1:cause_begin_charID+cause_length].split())-1\n",
    "                    for i, word in enumerate(text):\n",
    "                        if i >= begin_cause_wordID and i <= end_cause_wordID:\n",
    "                            if i == begin_cause_wordID:\n",
    "                                token_label[i] = 'B-CAU'\n",
    "                            else:\n",
    "                                token_label[i] = 'I-CAU'\n",
    "#                         else:\n",
    "#                             token_label[i] = 'O'\n",
    "                \n",
    "                if clause['_keywords'] == 'Y':\n",
    "                    emotion_begin_charID = int(clause['keywords']['_keywords-begin'])\n",
    "                    emotion_length = int(clause['keywords']['_keywords-lenth'])\n",
    "                    begin_emotion_wordID = len(clause['text'][:emotion_begin_charID-1].split())\n",
    "                    end_emotion_wordID = begin_emotion_wordID + len(clause['text'][emotion_begin_charID-1:emotion_begin_charID+emotion_length].split())-1\n",
    "                    for i, word in enumerate(text):\n",
    "                        if i >= begin_emotion_wordID and i <= end_emotion_wordID:\n",
    "                            if i == begin_emotion_wordID:\n",
    "                                token_label[i] = 'B-EMO'\n",
    "                            else:\n",
    "                                token_label[i] = 'I-EMO'\n",
    "                \n",
    "                for i, word in enumerate(text):\n",
    "                    if token_label[i] not in ['B-CAU', 'I-CAU', 'B-EMO', 'I-EMO', '[SEP]']:\n",
    "                        token_label[i] = 'O'\n",
    "                \n",
    "                \n",
    "            if text[-1] == '[SEP]':\n",
    "                token_label[-1] = '[SEP]'\n",
    "            \n",
    "            doc += text\n",
    "            doc_label += token_label\n",
    "        \n",
    "        assert len(doc) == len(doc_label)\n",
    "            \n",
    "        tsv_writer.writerow([' '.join(doc), ' '.join(doc_label), emotion])\n",
    "    \n",
    "    \n",
    "#     tsv_writer.writerow([['her', 'great'], ['O', 'B-emotion']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate labels for test file\n",
    "with open('./eca-test.tsv', 'wt') as out_file:\n",
    "    tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
    "    tsv_writer.writerow(['document', 'token_label', 'emotion-label'])\n",
    "    for d, document in enumerate(test_data['emotionml']['emotion']):\n",
    "        emotion = document['category']['_name']\n",
    "        doc = []\n",
    "        doc_label = []\n",
    "        if 'clause' not in test_data['emotionml']['emotion'][d]: continue\n",
    "        for i, clause in enumerate(test_data['emotionml']['emotion'][d]['clause']):\n",
    "            # raw text\n",
    "            if 'text' not in clause: continue\n",
    "            text = clause['text'].split(' ')  # a list of tokens\n",
    "            if i+1 != len(test_data['emotionml']['emotion'][d]['clause']):\n",
    "                text += ['[SEP]']\n",
    "            \n",
    "            # labels for each word in the raw data: 'O', 'B-CAU', 'I-CAU', 'B-EMO', 'I-EMO', '[CLS]', '[SEP]'\n",
    "            if clause['_cause'] == 'N' and clause['_keywords'] == 'N':\n",
    "                token_label = ['O'] * len(text)\n",
    "            else:\n",
    "                token_label = text.copy()\n",
    "                if clause['_cause'] == 'Y':\n",
    "                    cause_begin_charID = int(clause['cause']['_begin'])  # characater index\n",
    "                    cause_length = int(clause['cause']['_lenth'])\n",
    "                    begin_cause_wordID = len(clause['text'][:cause_begin_charID-1].split())  # word index for beginning\n",
    "                    end_cause_wordID = begin_cause_wordID + len(clause['text'][cause_begin_charID-1:cause_begin_charID+cause_length].split())-1\n",
    "                    for i, word in enumerate(text):\n",
    "                        if i >= begin_cause_wordID and i <= end_cause_wordID:\n",
    "                            if i == begin_cause_wordID:\n",
    "                                token_label[i] = 'B-CAU'\n",
    "                            else:\n",
    "                                token_label[i] = 'I-CAU'\n",
    "                \n",
    "                if clause['_keywords'] == 'Y':\n",
    "                    emotion_begin_charID = int(clause['keywords']['_keywords-begin'])\n",
    "                    emotion_length = int(clause['keywords']['_keywords-lenth'])\n",
    "                    begin_emotion_wordID = len(clause['text'][:emotion_begin_charID-1].split())\n",
    "                    end_emotion_wordID = begin_emotion_wordID + len(clause['text'][emotion_begin_charID-1:emotion_begin_charID+emotion_length].split())-1\n",
    "                    for i, word in enumerate(text):\n",
    "                        if i >= begin_emotion_wordID and i <= end_emotion_wordID:\n",
    "                            if i == begin_emotion_wordID:\n",
    "                                token_label[i] = 'B-EMO'\n",
    "                            else:\n",
    "                                token_label[i] = 'I-EMO'\n",
    "                \n",
    "                for i, word in enumerate(text):\n",
    "                    if token_label[i] not in ['B-CAU', 'I-CAU', 'B-EMO', 'I-EMO', '[SEP]']:\n",
    "                        token_label[i] = 'O'\n",
    "                \n",
    "                \n",
    "            if text[-1] == '[SEP]':\n",
    "                token_label[-1] = '[SEP]'\n",
    "            \n",
    "            doc += text\n",
    "            doc_label += token_label\n",
    "        \n",
    "        assert len(doc) == len(doc_label)\n",
    "            \n",
    "        tsv_writer.writerow([doc, doc_label, emotion])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
